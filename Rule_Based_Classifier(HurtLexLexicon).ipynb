{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7uZI3hE6BN5"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/Ar_PuFi.csv')\n",
        "new_lexicon = pd.read_csv('/content/New_Lexicon.csv')\n",
        "old_lexicon = pd.read_csv('/content/Old_Lexicon.csv')\n",
        "\n",
        "Offensive_comments = [comment for idx, comment in enumerate(df['Text']) \n",
        "               if df['Label'][idx] == '0']\n",
        "\n",
        "other_comments = [comment for idx, comment in enumerate(df['Text']) if df['Label'][idx] != '0']\n",
        "\n",
        "def evaluation(predictedHateComments, Offensive_comments, other_tweets):\n",
        "    FalsePositive = 0 \n",
        "    FalseNegative = 0\n",
        "    for comment in predictedHateComments:\n",
        "        if not comment in Offensive_comments:\n",
        "            FalsePositive+=1\n",
        "    TruePositive = len(predictedHateComments) - FalsePositive\n",
        "    \n",
        "    for comment in Offensive_comments:\n",
        "        if not comment in predictedHateComments:\n",
        "            FalseNegative+=1\n",
        "    TrueNegative = len(other_comments) - FalsePositive\n",
        "    \n",
        "    accuracy = float(TruePositive + TrueNegative)/float(TruePositive + FalsePositive + TrueNegative + FalseNegative)\n",
        "    precision = float(TruePositive)/float(TruePositive + FalsePositive)\n",
        "    recall = float(TruePositive)/float(TruePositive + FalseNegative)\n",
        "    f1_score = 2*((precision*recall)/(precision+recall))\n",
        "    \n",
        "    return accuracy, precision, recall, f1_score\n",
        "\n",
        "old_predictedHateComments = []\n",
        "for comment in df['Text']:\n",
        "    for word in old_lexicon['clean']:\n",
        "        if word in str(comment):\n",
        "            old_predictedHateComments.append(comment)\n",
        "            break\n",
        "accuracy, precision, recall, f1_score = evaluation(old_predictedHateComments, Offensive_comments, other_comments)\n",
        "print (\"accuracy : %.4f, precision : %.4f, recall : %.4f, f1_score : %.4f\" %(accuracy, precision,recall,f1_score))\n",
        "\n",
        "predictedHateComments = []\n",
        "for comment in df['Text']:\n",
        "    for word in new_lexicon['clean']:\n",
        "        if word in str(comment):\n",
        "            predictedHateComments.append(comment)\n",
        "            break\n",
        "accuracy, precision, recall, f1_score = evaluation(predictedHateComments, Offensive_comments, other_comments)\n",
        "print (\"accuracy : %.4f, precision : %.4f, recall : %.4f, f1_score : %.4f\" %(accuracy, precision,recall,f1_score))\n",
        "import nltk\n",
        "\n",
        "dataset_words = []\n",
        "for comment in df['Text']:\n",
        "    for word in str(comment).split(\" \"):\n",
        "        dataset_words.append(word)\n",
        "len(dataset_words)\n",
        "\n",
        "Offensive_Language_words = []\n",
        "for comment in Offensive_comments:\n",
        "    for word in str(comment).split(\" \"):\n",
        "        Offensive_Language_words.append(word)\n",
        "\n",
        "all_fdist = nltk.FreqDist(word for word in dataset_words)\n",
        "offensive_fdist = nltk.FreqDist(word for word in Offensive_Language_words)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "all_fdist.plot(30)\n",
        "\n",
        "offensive_fdist.plot(30)\n",
        "\n",
        "old_lex_dist = {}\n",
        "for word in set(old_lexicon['clean']):\n",
        "    old_lex_dist[word] = offensive_fdist[word]\n",
        "\n",
        "old_lex_tuple = [(value, key) for key, value in old_lex_dist.items()]\n",
        "old_lex_tuple.sort(key=lambda tup: tup[0], reverse=True)\n",
        "old_lex_tuple\n",
        "\n",
        "new_lex_dist ={}\n",
        "for word in set(new_lexicon['clean']):\n",
        "    new_lex_dist[word] = offensive_fdist[word]\n",
        "\n",
        "new_lex_tuple = [(value, key) for key, value in new_lex_dist.items()]\n",
        "new_lex_tuple.sort(key=lambda tup: tup[0], reverse=True)\n",
        "new_lex_tuple\n",
        "plt.plot(list(old_lex_dist.values()))\n",
        "plt.plot(list(new_lex_dist.values()))\n",
        "\n",
        "old_word_cat = dict()\n",
        "for cat in set(old_lexicon['category']):\n",
        "    old_word_cat[cat]= 0\n",
        "for idx, word in enumerate(old_lexicon['clean']): \n",
        "    old_word_cat[old_lexicon['category'][idx]]+= offensive_fdist[word]\n",
        "old_catCount = [(cat, count) for cat,count in old_word_cat.items()]\n",
        "old_catCount.sort(key=lambda tup: tup[1], reverse=True)\n",
        "old_catCount\n",
        "\n",
        "new_word_cat = dict()\n",
        "for cat in set(new_lexicon['category']):\n",
        "    new_word_cat[cat]= 0\n",
        "for idx, word in enumerate(new_lexicon['clean']): \n",
        "    new_word_cat[new_lexicon['category'][idx]]+= offensive_fdist[word]\n",
        "new_catCount = [(cat, count) for cat,count in new_word_cat.items()]\n",
        "new_catCount.sort(key=lambda tup: tup[1], reverse=True)\n",
        "new_catCount\n",
        "\n",
        "def hatful_offinsive(Offinsive_comments):\n",
        "    hatful_offinsive_comments = []\n",
        "    for comment in set(Offinsive_comments):\n",
        "        for word in new_lexicon['clean']:\n",
        "            if word in comment:\n",
        "                hatful_offinsive_comments.append(comment)\n",
        "                break\n",
        "    return hatful_offinsive_comments\n",
        "hatful_offinsive_comments = hatful_offinsive(Offinsive_comments)\n",
        "hatful_not_offinsive_comments = set(Offinsive_comments) - set(hatful_offinsive_comments)\n",
        "hatful_not_offinsive_comments"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}