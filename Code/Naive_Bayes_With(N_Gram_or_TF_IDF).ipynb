{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evavjP3jjxQt"
      },
      "source": [
        "# **Important Installations & Dependencies**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuITAb7bJZgU"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "!pip install farasapy\n",
        "from farasa.stemmer import FarasaStemmer\n",
        "from sklearn.model_selection  import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score, precision_score,recall_score\n",
        "from sklearn.metrics import classification_report as creport\n",
        "from multiprocessing import Pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa7-DN6vU53M"
      },
      "source": [
        "### **Load the Binary Datset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2cBUWdu9N63-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "df= pd.read_excel(io.BytesIO(uploaded['BinaryPublicFigures.xlsx'])) \n",
        "df= df[['Text','Label']]\n",
        "df"
      ],
      "metadata": {
        "id": "iPDqgXk_IsYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the Multi Datset**"
      ],
      "metadata": {
        "id": "QaNP2VGsPEW1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci4Iyu40gDOX"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded= files.upload ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4oPqx3CK9wa"
      },
      "source": [
        "# import io\n",
        "# Art= pd.read_excel(io.BytesIO(uploaded['Art.xlsx']))\n",
        "# Art= Art[['Text','Label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT3hAyvcgEeY"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded= files.upload ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W564saudgNm9"
      },
      "source": [
        "# import io\n",
        "# Business= pd.read_excel(io.BytesIO(uploaded['Business.xlsx']))\n",
        "# Business= Business[['Text','Label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWdQy28cgH0C"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded= files.upload ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oHdahBOgOzu"
      },
      "source": [
        "# import io\n",
        "# Politics= pd.read_excel(io.BytesIO(uploaded['Politics.xlsx']))\n",
        "# Politics= Politics[['Text','Label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VNjnEs3gH6S"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded= files.upload ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k56F-rHLgPV_"
      },
      "source": [
        "# import io\n",
        "# Judiciary= pd.read_excel(io.BytesIO(uploaded['Judiciary.xlsx']))\n",
        "# Judiciary= Judiciary[['Text','Label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP2PpwfhgIAi"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded= files.upload ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXIN6mc8gPvf"
      },
      "source": [
        "# import io\n",
        "# Sports= pd.read_excel(io.BytesIO(uploaded['Sports.xlsx']))\n",
        "# Sports= Sports[['Text','Label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJsFbVuegIGq"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded= files.upload ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFtB-HFUgQN3"
      },
      "source": [
        "# import io\n",
        "# Literature= pd.read_excel(io.BytesIO(uploaded['Literature.xlsx']))\n",
        "# Literature= Literature[['Text','Label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqfiiTXxLXOK"
      },
      "source": [
        "# Business = Business[Business['Label'] == 0]\n",
        "# Literature = Literature[Writer['Label'] == 0]\n",
        "# Sports = Sports[Sports['Label'] == 0]\n",
        "# Judiciary = Judiciary[Judiciary['Label'] == 0]\n",
        "# Politics = Politics[Politics['Label'] == 0]\n",
        "# Art = Art[Art['Label'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71MjIkeoLXOK"
      },
      "source": [
        "# Literature['Label'] = Literature['Label'].replace([0],[1])\n",
        "# Sports['Label'] = Sports['Label'].replace([0],[2])\n",
        "# Judiciary['Label'] = Judiciary['Label'].replace([0],[3])\n",
        "# Politics['Label'] = Politics['Label'].replace([0],[4])\n",
        "# Art['Label'] = Art['Label'].replace([0],[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frames= [Literature,Sports, Judiciary, Politics, Art, Business]\n",
        "# df= pd.concat(frames)"
      ],
      "metadata": {
        "id": "1pbL5geITf0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "OITAwuokUHdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df[\"Label\"] = df[\"Label\"].astype(str).astype(int)\n",
        "# dataTypeObj = df.dtypes['Label']\n",
        "# print(dataTypeObj)"
      ],
      "metadata": {
        "id": "Be8D4gUfofmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOjj6XvckTSB"
      },
      "source": [
        "# **Data Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTEWf1FbyXxu"
      },
      "source": [
        "def clean(df):\n",
        "    df = remove_diacritics(df)\n",
        "    df = normalize_arabic(df)\n",
        "    df = remove_punctuations(df)\n",
        "    df = remove_repeating_char(df)\n",
        "    df= remove_english_word_and_numbers(df)\n",
        "    df=clean_space(df)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y2ur_EkyeQy"
      },
      "source": [
        "arabic_punctuations = '''`÷« »×؛<>٩٨'٧٦٥٤٣٢١٠_()↗*•&^%][ـ،/:\"؟.,'{}⋮≈~¦+|٪!”…“–ـ/[]%=#*+\\\\•~@£·_{}©^®`→°€™›♥←×§″′Â█à…“★”–●â►−¢¬░¶↑±▾\t═¦║―¥▓—‹─▒：⊕▼▪†■’▀¨▄♫☆é¯♦¤▲è¸Ã⋅‘∞∙）↓、│（»，♪╩╚³・╦╣╔╗▬❤ïØ¹≤‡₹´'''\n",
        "english_punctuations = string.punctuation\n",
        "punctuations_list = arabic_punctuations + english_punctuations\n",
        "\n",
        "arabic_diacritics = re.compile(\"\"\"\n",
        "                             ّ    | # Tashdid\n",
        "                             َ    | # Fatha\n",
        "                             ً    | # Tanwin Fath\n",
        "                             ُ    | # Damma\n",
        "                             ٌ    | # Tanwin Damm\n",
        "                             ِ    | # Kasra\n",
        "                             ٍ    | # Tanwin Kasr\n",
        "                             ْ    | # Sukun\n",
        "                             ـ     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODlY489hyuNN"
      },
      "source": [
        "def remove_diacritics(df):\n",
        "    df['Text'] = df['Text'].apply(lambda x: _remove_diacritics(x))\n",
        "    return df\n",
        "def _remove_diacritics(x):\n",
        "    x = str(x)\n",
        "    x = re.sub(arabic_diacritics, '', x)\n",
        "    return x\n",
        "\n",
        "def normalize_arabic(df):\n",
        "    df['Text'] = df['Text'].apply(lambda x: _normalize_arabic(x))\n",
        "    return df\n",
        "def _normalize_arabic(x):\n",
        "    x = str(x)\n",
        "    # added space around puncts after replace\n",
        "    x = re.sub(\"[إأآا]\", \"ا\", x)\n",
        "    x = re.sub(\"ى\", \"ي\", x)\n",
        "    x = re.sub(\"ؤ\", \"ء\", x)\n",
        "    x = re.sub(\"ئ\", \"ء\", x)\n",
        "    x = re.sub(\"ة\", \"ه\", x)\n",
        "    x = re.sub(\"گ\", \"ك\", x)\n",
        "    return x\n",
        "\n",
        "def remove_punctuations(df):\n",
        "    df['Text'] = df['Text'].apply(lambda x: _remove_punctuations(x))\n",
        "    return df\n",
        "def _remove_punctuations(x):\n",
        "    x = str(x)\n",
        "    #translator = str.maketrans(' ', ' ', punctuations_list)\n",
        "    translator = str.maketrans(punctuations_list, ' '*len(punctuations_list))\n",
        "    return x.translate(translator)\n",
        "\n",
        "def remove_repeating_char(df):\n",
        "    df['Text'] = df['Text'].apply(lambda x: _remove_repeating_char(x))\n",
        "    return df\n",
        "def _remove_repeating_char(x):\n",
        "    x = str(x)\n",
        "    return re.sub(r'(.)\\1+', r'\\1', x)\n",
        "\n",
        "def remove_english_word_and_numbers(df):\n",
        "    df['Text'] = df['Text'].apply(lambda x: _remove_english_word_and_numbers(x))\n",
        "    return df\n",
        "def _remove_english_word_and_numbers(x):\n",
        "    x = str(x)\n",
        "    return re.sub(r'[a-zA-Z0-9]+', '', x)\n",
        "\n",
        "def clean_space(df):\n",
        "    compiled_re = re.compile(r\"\\s+\")\n",
        "    df['Text'] = df[\"Text\"].apply(lambda x: _clean_space(x, compiled_re))\n",
        "    return df\n",
        "def _clean_space(x, compiled_re):\n",
        "    return compiled_re.sub(\" \", x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvWj2NZcwdKD"
      },
      "source": [
        "text_a=df['Text'].values.tolist()\n",
        "print(len(text_a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS8bux9gxvY-"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words= stopwords.words('arabic')\n",
        "for index,text_ in enumerate(text_a):\n",
        "    text_=\" \".join(i for i in text_.split() if i not in stop_words) #Removing stopword\n",
        "    text_a[index]=text_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxfZjOmFvYf_"
      },
      "source": [
        "#Stemming the word\n",
        "stemmer = FarasaStemmer(interactive=True)\n",
        "for index,text_ in enumerate(text_a):\n",
        "    text_=\" \".join(stemmer.stem(i) for i in text_.split())   \n",
        "    text_a[index]=text_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i55KUVbMaRHT"
      },
      "source": [
        "df['Text']=text_a[:len(df)]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqmgO_XDzILE"
      },
      "source": [
        "num_cores = 2\n",
        "def df_parallelize_run(df, func, num_cores=2):\n",
        "    df_split = np.array_split(df, num_cores)\n",
        "    pool = Pool(num_cores)\n",
        "    df = pd.concat(pool.map(func, df_split))\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m870svOszLGn"
      },
      "source": [
        "df = df_parallelize_run(df, clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= shuffle(df,random_state=0)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "EXDSdPu3JKGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_test = train_test_split(df,test_size = 0.2)"
      ],
      "metadata": {
        "id": "YZIA0TPaJOEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.to_csv(\"data_train.csv\", index=False)\n",
        "!cp -R data_train.csv \"/content/drive/MyDrive/DatasetCleaned\"\n",
        "data_test.to_csv(\"data_test.csv\", index=False)\n",
        "!cp -R data_test.csv \"/content/drive/MyDrive/DatasetCleaned\" "
      ],
      "metadata": {
        "id": "8WH7t-3oJgyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBYS-8uTznar"
      },
      "source": [
        "# **Training & Testing**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTn4UNFMKQUb"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/DatasetCleaned/data_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcxWn8RAJpTI"
      },
      "source": [
        "x=dataset.iloc[:,0]\n",
        "y=dataset.iloc[:,1]\n",
        "X=x.to_dict()\n",
        "\n",
        "X=[]\n",
        "for d in range(len(x)):\n",
        "    b=x[d]\n",
        "    X.append(b) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zxndc1XKlsJ"
      },
      "source": [
        "count_vect=CountVectorizer()\n",
        "X_train_counts=count_vect.fit_transform(X)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf= X_train_tfidf.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHjD4YI0K7I3"
      },
      "source": [
        "clf= naive_bayes.BernoulliNB()\n",
        "clf.fit(X_train_tfidf, y)\n",
        "clf.score(X_train_tfidf, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUevBk3jLSsh"
      },
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/DatasetCleaned/data_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY-Vle45PZnD"
      },
      "source": [
        "x_test=test_data.iloc[:,0]\n",
        "y_test=test_data.iloc[:,1]\n",
        "X=x_test.to_dict()\n",
        "\n",
        "X=[]\n",
        "for d in range(len(x)):\n",
        "    b=x[d].lower()\n",
        "    X.append(b)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uotO18mPPotP"
      },
      "source": [
        "X_test_tfidf=count_vect.transform(x_test)\n",
        "y_pred=clf.predict(X_test_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NB weighted-averaged precision-score -> \",precision_score(y_test, y_pred,average=\"binary\", pos_label=\"1\"))\n",
        "print(\"NB weighted-averaged recall-score -> \",recall_score(y_test, y_pred,average=\"binary\", pos_label=\"1\"))\n",
        "print(\"NB weighted-averaged F1-score -> \",f1_score(y_test, y_pred,average=\"binary\", pos_label=\"1\"))"
      ],
      "metadata": {
        "id": "X11Pg1CqR2Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DohnKD7m3Fvs"
      },
      "source": [
        "print(creport(y_test, y_pred,target_names=['Offensive', 'Benign'],digits=4)) # Forthe Binary dataset \n",
        "# print(creport(y_test, y_pred,target_names=['Literature,Sports, Judiciary, Politics, Art, Business'],digits=4)) // For Multi dataset"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}