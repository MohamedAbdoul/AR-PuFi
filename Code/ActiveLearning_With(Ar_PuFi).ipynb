{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEsLe56de_Kw"
      },
      "outputs": [],
      "source": [
        "%pip install small-text[transformers]  # use \"small-text\" without \"[transformers]\" if you want to work on the CPU only\n",
        "%pip install datasets\n",
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7x9LB6Gf6V0"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import logging\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKo7SE3UgiBh"
      },
      "outputs": [],
      "source": [
        "# disables the progress bar for notebooks: https://github.com/huggingface/datasets/issues/2651\n",
        "datasets.logging.get_verbosity = lambda: logging.NOTSET\n",
        "num_classes = 2 # change to 6 when use the Ar_PuFi Multi dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml3T_wbPh7vX"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhOtXUSZiA9T"
      },
      "outputs": [],
      "source": [
        "transformer_model_name = 'asafaya/bert-base-arabic'\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    transformer_model_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt3a3g9ViuZQ"
      },
      "outputs": [],
      "source": [
        "from small_text.integrations.transformers.datasets import TransformersDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def get_transformers_dataset(tokenizer, data, labels, max_length=100):\n",
        "\n",
        "    data_out = []\n",
        "\n",
        "    for i, doc in enumerate(data):\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            doc,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation='longest_first'\n",
        "        )\n",
        "\n",
        "        data_out.append((encoded_dict['input_ids'], encoded_dict['attention_mask'], labels[i]))\n",
        "\n",
        "    return TransformersDataset(data_out)\n",
        "from sklearn.model_selection import train_test_split\n",
        "df= pd.read_csv('/content/Ar_PuFi.csv')\n",
        "train_, test_ = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_text = train_[\"Text\"].tolist()\n",
        "train_labels=train_[\"Label\"].tolist()\n",
        "test_text = test_[\"Text\"].tolist()\n",
        "test_labels=test_[\"Label\"].tolist()\n",
        "train = get_transformers_dataset(tokenizer, train_text, train_labels)\n",
        "test = get_transformers_dataset(tokenizer, test_text, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQAi6uUPkGk3"
      },
      "source": [
        "**Pool Based Active Learner**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vPCvP-ikLWA"
      },
      "outputs": [],
      "source": [
        "from small_text.active_learner import PoolBasedActiveLearner\n",
        "from small_text.initialization import random_initialization_balanced\n",
        "from small_text.integrations.transformers import TransformerModelArguments\n",
        "from small_text.integrations.transformers.classifiers.factories import TransformerBasedClassificationFactory\n",
        "from small_text.query_strategies import PredictionEntropy\n",
        "from small_text.integrations.transformers import TransformerModelArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB-5UhuikykD"
      },
      "outputs": [],
      "source": [
        "# simulates an initial labeling to warm-start the active learning process, ChanGING THE SAMPLE SIZE TO 15\n",
        "def initialize_active_learner(active_learner, y_train):\n",
        "    x_indices_initial = random_initialization_balanced(y_train, n_samples=960)\n",
        "    y_initial = y_train[x_indices_initial]\n",
        "\n",
        "    active_learner.initialize_data(x_indices_initial, y_initial)\n",
        "\n",
        "    return x_indices_initial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsEC_zvUmnCk"
      },
      "outputs": [],
      "source": [
        "transformer_model = TransformerModelArguments(transformer_model_name)\n",
        "clf_factory = TransformerBasedClassificationFactory(transformer_model, \n",
        "                                                    num_classes, \n",
        "                                                    kwargs=dict({'device': 'cuda', \n",
        "                                                                 'mini_batch_size': 32,\n",
        "                                                                 'early_stopping_no_improvement': -1\n",
        "                                                                }))\n",
        "query_strategy = PredictionEntropy()\n",
        "active_learner = PoolBasedActiveLearner(clf_factory, query_strategy, train)\n",
        "labeled_indices = initialize_active_learner(active_learner, train.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGpqe00z0M_E"
      },
      "source": [
        "**Active Learning Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjsg2bL-0J-0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "\n",
        "\n",
        "num_queries = 24\n",
        "\n",
        "#Evaulate Function \n",
        "def evaluate(active_learner, train, test):\n",
        "    y_pred = active_learner.classifier.predict(train)\n",
        "    y_pred_test = active_learner.classifier.predict(test)\n",
        "    \n",
        "    test_acc = accuracy_score(y_pred_test, test.y)\n",
        "    test_precision = precision_score(y_pred_test, test.y)\n",
        "    test_recall = recall_score(y_pred_test, test.y)\n",
        "    test_F_score = f1_score(y_pred_test, test.y)\n",
        "\n",
        "    #confustion_matrix_dis = confusion_matrix(y_pred_test, test.y)\n",
        "\n",
        "    # print('Train accuracy: {:.2f}'.format(accuracy_score(y_pred, train.y)))\n",
        "    print('Test accuracy: {:.2f}'.format(test_acc))\n",
        "    # print('Train Precision: {:.2f}'.format(precision_score(y_pred, train.y)))\n",
        "    print('Test Precision: {:.2f}'.format(test_precision))\n",
        "    # print('Train Recall: {:.2f}'.format(recall_score(y_pred, train.y)))\n",
        "    print('Test Recall: {:.2f}'.format(test_recall))\n",
        "    print('Test f_score: {:.2f}'.format(test_F_score))\n",
        "\n",
        "    \n",
        "    #print\n",
        "    \n",
        "    return test_acc, test_precision, test_recall,test_F_score\n",
        "\n",
        "\n",
        "results = []\n",
        "results.append(evaluate(active_learner, train[labeled_indices], test))\n",
        "\n",
        "for i in range(num_queries):\n",
        "    # ...where each iteration consists of labelling 960 samples\n",
        "    q_indices = active_learner.query(num_samples=960)\n",
        "\n",
        "    # Simulate user interaction here. Replace this for real-world usage.\n",
        "    y = train.y[q_indices]\n",
        "\n",
        "    # Return the labels for the current query to the active learner.\n",
        "    active_learner.update(y)\n",
        "\n",
        "    labeled_indices = np.concatenate([q_indices, labeled_indices])\n",
        "\n",
        "    print('Iteration #{:d} ({} samples)'.format(i, len(labeled_indices)))\n",
        "    results.append(evaluate(active_learner, train[labeled_indices], test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MsefBqmUcrHe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}